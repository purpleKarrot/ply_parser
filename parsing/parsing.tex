\documentclass[a4paper, parskip=half, twocolumn]{scrartcl}
%
\usepackage{geometry}
\geometry{a4paper,left=25mm,right=25mm, top=25mm, bottom=25mm} 
\setlength{\columnsep}{10mm}

%\usepackage{a4wide}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}

\usepackage[numbers]{natbib}
\usepackage{csquotes}

\usepackage{listings}
\lstset{basicstyle=\ttfamily\scriptsize\mdseries}

\usepackage{hyperref}
\hypersetup{colorlinks=true}
\urlstyle{same}

\title{Type-Safe Parsing with a Dynamic Grammar}

\author{Daniel Pfeifer,
\href{mailto:daniel@pfeifer-mail.de}{daniel@pfeifer-mail.de} \\
Department of Informatics (IFI), University of Zurich}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
In computer science, parsing is the process of analyzing a sequence of tokens
(words, bytes or even single bits) with respect to a formal grammar. The way
the analyzed data is processed is called semantics.

Parsers may be crafted by hand or generated by a tool that generates source code
from specification in a formal language. Both of these approaches require a
complete knowlegde of the data to be parsed.

In this paper I am going to present an approach of building a parser from a
dynamic grammar and static semantics. This allows to specify the data to be
parsed at runtime, but still provides static type safety. As an example
application, I wrote a parser for the PLY file format using the techniques
described in this paper.
\end{abstract}

\input{1_introduction}
\input{2_related_work}
\input{3_generic_parsing}
\input{4_generic_programming}
\input{5_implementation}
\input{6_ply_example}
\input{7_conclusion}

\section{Approach}
\subsection{Motivating Example}
An example data structure is
given in Listing \ref{vertex}. This data structure directly affects the
semantics of the parser.

\begin{lstlisting}[frame=tb,label=vertex,caption=Vertex Example]
struct vertex
{
  float x, y, z;
  uchar b, g, r;
};
\end{lstlisting}

We have a file that contains a list of vertices. Each vertex consists of a
position and a color. The position is given as two double precision floating
point numbers and the color is in ARGB format, where each color channel is an
unsigned char. The list of vertices should be parsed, and written into an array
of the vertex struct introduced in Listing \ref{vertex}.

The parser should be able to match these seven numbers in the format that is
specified in the header, convert the first two numbers to float, assign the
values to the corresponding elements of the struct (taking reordering into
account), set the element z to a default and discard the alpha channel of the
color.

\subsection{Motivating Example}



\subsection{Motivating Example}





\section{Custom Approach}

The two reviewed libraries do not provide the safety and ease of use that are
desired for a parser to be used in a parallel rendering application. I propose
another approach, that is completely typesafe and requires only a minimum of
setup. It is still flexible enough to read from any kind on input like
compressed files or network streams.

My library uses the Qi parser library which allows to write grammars and format
descriptions using a format similar to Extended Backus Naur Form (EBNF) directly
in C++. The grammar to parse the PLY file header is summarized in Listing 1.


Building a parser from this grammar is straight forward with both Lex/YACC and
Qi. The grammar to parse the file body cannot be known at compile time and has
to be constructed after the header has been parsed. In this context Qi's
expression templates win over Lex/YACC.

Using my library, the user has to register neither types nor callback functions.
The only requirement is that the PLY elements are assigned to an object whose
type models the \emph{Sequence} concept of the Boost.Fusion library.

Any custom struct can be adapted by the macro
\texttt{BOOST\_FUSION\_ADAPT\_STRUCT} to fulfill this requirement without
modifying the struct itself . All further required information, even the
property names, are deduced by applying template metaprogramming techniques
described in \cite{Abrahams:2004:CTM:1044941} and the documentation of
Fusion\footnote{\url{http://www.boost.org/doc/libs/release/libs/fusion/}}.

\subsection{Generic Programming Techniques}

The function \texttt{std::copy()} copies a range of data of a generic type,
provided that the input parameters model \emph{Input Iterator} and the output
parameter models \emph{Output Iterator}. To extract a chunk, one can either
\begin{itemize}
  \item increment the input parameter to the desired begin of the chunk and then
  copy all data before the desired end or
  \item provide a custom output iterator type that skips data before the chunk.
\end{itemize}

Loading different chunks successively is a multipass algorithm. Multipass
algorithms require the iterators to model \emph{Forward Iterator} which is a
refinement of \emph{Input Iterator}.

Iterators of the C++ Standard Library that read from an input stream model the
\emph{Input Iterator} concept. The class \texttt{boost::spirit::multi\_pass} of
the Boost.Spirit library wraps any input iterator and models \emph{Forward
Iterator} by the use of reference counted buffers.

This class should be used with care. It is intended to support backtracking in
parsing grammars that contain alternatives. Improper use of this class can lead
to buffering the complete stream in the worst case.

\subsection{Reused and reusable parts}

The implementation of the library contains parts that are not specific to
parsing PLY files, but can be reused to implement parsers that load files with
similar content but different grammar:

\begin{itemize}
  \item A parser class that wraps a grammar and a range of \emph{Forward
  Iterator}s. The class provides an invocation function that parses the
  grammatical expression once.
  \item A wrapper class around such a parser that models the \emph{Input
  Iterator} concept. The wrapped parser is invocated each time the iterator is
  incremented. It allows to copy parsed data to any output while parsing on the
  fly.
  \item A model of \emph{Output Iterator} that wraps another \emph{Output
  Iterator} and two indices defining the \emph{range of interest}. Outside the
  range of interest the wrapped iterator is not incremented and assignments are
  silently consumed. This class can be used to extract chunks from a stream.
\end{itemize}

A few other reusable components that have been used in the implementation
already are available in different libraries:

\begin{itemize}
  \item Streams that decompress data on the fly are provided by Boost.Iostreams.
  \item A class that wraps an \emph{Input Iterator} range and models the
  \emph{Forward Iterator} concept is provided by Boost.Spirit.
  \item An iterator class that stores information about the current position to
  provide helpful error messages when parsing fails is provided by Boost.Spirit.
\end{itemize}

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
